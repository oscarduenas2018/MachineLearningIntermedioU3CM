{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Proyecto 1\n",
    "\n",
    "## Aprendizaje Automático Intermedio e Ingeniería de Características\n",
    "\n",
    "### Enero 2023\n",
    "\n",
    "**Emilio Parrado Hernández, Vanessa Gómez Verdejo, Pablo Martínez Olmos**\n",
    "\n",
    "Departamento de Teoría de la Señal y Comunicaciones\n",
    "\n",
    "**Universidad Carlos III de Madrid**\n",
    "\n",
    "<img src='http://www.tsc.uc3m.es/~emipar/BBVA/INTRO/img/logo_uc3m_foot.jpg' width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos y comprensión de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Pandas requires version '2.0.1' or newer of 'xlrd' (version '1.2.0' currently installed).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-89bb146fcbf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m df = pd.read_excel(data_sheet,\n\u001b[0m\u001b[0;32m      5\u001b[0m                   \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \"\"\"\n\u001b[0;32m     33\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Pandas requires version '2.0.1' or newer of 'xlrd' (version '1.2.0' currently installed)."
     ]
    }
   ],
   "source": [
    "data_sheet = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls'\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(data_sheet,\n",
    "                  header=1,\n",
    "                skiprows=0,\n",
    "                  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de las variables de entrada\n",
    "\n",
    "Esta es la descripción extraída de la web de la que se descargan los datos\n",
    "\n",
    "- This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. \n",
    "- This study reviewed the literature and used the following 23 variables as explanatory variables:\n",
    "    - X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "    - X2: Gender (1 = male; 2 = female).\n",
    "    - X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "    - X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "    - X5: Age (year).\n",
    "    - X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -2=no consumption, -1=pay duly, 0=the use of revolving credit, 1=payment delay for one month, 2=payment delay for two months, … 8=payment delay for eight months, 9=payment delay for nine months and above\n",
    "    - X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "    - X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimir un registro para ver en detalle cada campo\n",
    "df.loc[1568]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de variables\n",
    "\n",
    "Algunas de las variables categóricas presentan valores que no aparecen en la descripción\n",
    "\n",
    "### Education y Marriage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_cat = ['EDUCATION','MARRIAGE']\n",
    "for cc in columns_cat:\n",
    "    print(cc)\n",
    "    print(df[cc].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que aparecen valores que no están en la descripción, vamos a *limpiar* estas variables agrupando del siguiente modo:\n",
    "- `EDUCATION`: pasar los valores $\\{0, 5, 6\\}$ a $4$ (`others`)\n",
    "- `MARRIAGE`: pasar el valor $0$ a $3$ (`others`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'EDUCATION'] = df.loc[:,'EDUCATION'].apply(lambda x: 4 if x==0 else x)\n",
    "df.loc[:,'EDUCATION'] = df.loc[:,'EDUCATION'].apply(lambda x: 4 if x>=4 else x)\n",
    "df.loc[:,'MARRIAGE'] = df.loc[:,'MARRIAGE'].apply(lambda x: 3 if x==0 else x)\n",
    "for cc in columns_cat:\n",
    "    print(cc)\n",
    "    print(df[cc].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sacar discretas de PAY_0 a PAY_6 (3%)\n",
    "\n",
    "Las variables `PAY_0` a `PAY_6` tienen una interpretación mixta entre categórica y numérica. Los valores $\\{-2, -1 ,0\\}$ pueden considerarse categóricos, mientras que los valores positivos pueden considerarse numéricos.\n",
    "\n",
    "Vamos a codificarlas de modo categórico con las siguientes categorías:\n",
    "- `PAY_X` $=-2$: no consumption\n",
    "- `PAY_X` $=-1$: pay duly  \n",
    "- `PAY_X` $=0$:  use of revolving credit\n",
    "- `PAY_X` $ >0$: payment delay\n",
    "\n",
    "Básicamente tenéis que escribir código que:\n",
    " - transforme todos los valores positivos en un solo valor, por ejemplo $1$\n",
    " - añanda columnas `PAY_X_dis` al dataframe con esos valores discretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-806dd8b88c91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PAY'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'dis'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PAY'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "import numpy as np\n",
    "for i in np.delete(np.arange(7),1): \n",
    "        df.loc[:,'PAY'+str(i)+'dis'] = df.loc[:,'PAY'+str(i)].apply(lambda x: 1 if x>0 else x)\n",
    "    \n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición en entrenamiento y test (2%)\n",
    "\n",
    "Divida los datos aleatoriamente en dos dataframes con la siguiente distribución de tamaños:\n",
    "- `train_df`: Entrenamiento 20K\n",
    "- `test_df`: Test 10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "####### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train {0:d} ejemplos\".format(len(train_df)))\n",
    "print(\"Test {0:d} ejemplos\".format(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación trivial (5%)\n",
    "\n",
    "El primer paso es establecer el clasificador *baseline* contra el que vamos a comparar los resultados de los modelos que vayamos entrenando a lo largo del *notebook*.\n",
    "\n",
    "Este resultado depende de si las clases están o no desbalanceadas. **Analizad el desbalanceo en el dataframe** `train_df` y elegid el resultado del clasificador *baseline*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "####### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regresión Logística con variables numéricas\n",
    "\n",
    "El primer modelo que vamos a construir es un clasificador basado en [**regresión logística**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) sólo empleando como entradas las variables numéricas. \n",
    "\n",
    "## 1.1 Identificar variables numéricas (5%)\n",
    "Construid una lista de python llamada `num_var` con las variables numéricas (las que no son categóricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "num_var = [var in df.columns if len(np.unique(df[var]))]\n",
    "num_var\n",
    "\n",
    "#######\n",
    "# END #\n",
    "####### \n",
    "print(\"Variables numéricas\")\n",
    "print(num_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Construir el modelo de regresión logística solo con las variables numéricas (10%)\n",
    "\n",
    "- Usad `Pipeline` y `GridSearchCV` para introducir un escalado como preprocesado, si lo veis oportuno.\n",
    "- Usad los siguientes nombres para los numpy arrays con los que llaméis los métodos (`fit`, `sore`, `predict`,etc) del regresor logístico:\n",
    "    - `X_train`\n",
    "    - `Y_train`\n",
    "    - `X_test`\n",
    "    - `Y_test`\n",
    "- Comparad el resultado del modelo en el conjunto de test con la solución trivial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-d45d93138eca>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-d45d93138eca>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    lr_pipe =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "from sklearn.linear_model import LogistcRegression\n",
    "from sklearn.preprocessing import StandardScaler.MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_pipe = Pipeline([('scaler',MinMaxScaler()),\n",
    "                   ('clf', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "param_piep = {'scaler' : [StandardScaler(),'passtrough']}\n",
    "grid_lr_pipe = GridSearchCV(lr_pipe, param == params_pipe, cv = 5)\n",
    "\n",
    "x_train= train_df[num_var].dropna().values\n",
    "x_test= train_df[num_var].dropna().values\n",
    "y_train= train_df['default_payment'].dropna().values\n",
    "y_test= train_df['default_payment'].dropna().values\n",
    "\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Pintar pesos y dar interpretación (5%)\n",
    "\n",
    "Imprimid los pesos del regresor logístico con el nombre de la variable correspondiente\n",
    "\n",
    "- Peso w0: XXX.XX\n",
    "- peso Variable1: YYY.YY\n",
    "- ...\n",
    "- peso VariableM: ZZZZ.ZZZZ\n",
    "\n",
    "y comentad la relevancia de cada variable en la clasificación. Puede ser de ayuda imprimir los pesos ordenados por valor absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Curva ROC (10%)\n",
    "\n",
    "Dibujar la [curva ROC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) del clasificador anterior y calcular el [área bajo la curva](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html). Usad el conjunto de test para este apartado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Transformación logarítmica de las variables numéricas y comparar (5%)\n",
    "\n",
    "Para controlar el impacto de los rangos de las variables numéricas vamos a emplear una transformación logarítmica. Como hay valores que pueden ser negativos, y el logaritmo sólo está definido para valores positivos, vamos a extender la transformación de modo que:\n",
    "$$\n",
    "y(x) = \\mbox{signo}(x) \\log_{10}(x)\n",
    "$$\n",
    "\n",
    "Escriba código que:\n",
    "- Aplique la siguiente función para hacer la transformación de los numpy arrays `X_train` y `X_test` en `LXtrain` y `LXtest`.\n",
    "- Entrene un modelo de regresión logística con las variables transformadas\n",
    "- Compare el acierto de este modelo con el baseline y con el modelo anterior\n",
    "- Pinte la curva ROC de este modelo y calcule el área bajo la curva\n",
    "- Imprima los valores de los pesos del modelo correspondiente a cada variable \n",
    "\n",
    "Discuta las diferencias entre este modelo y el anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_transform(x):\n",
    "    negativos = x <0\n",
    "    ceros = x == 0\n",
    "    ax = np.absolute(x)\n",
    "    ax[ceros] = 1\n",
    "    Lx = np.log10(ax)\n",
    "    Lx[negativos] = -Lx[negativos]\n",
    "    Lx[ceros] = 0\n",
    "    return Lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 1.6 Combinaciones de variables numéricas, extensión polinómica y de ratios (5%)\n",
    "\n",
    "Para completar el análisis de las variables numéricas vamos a extender las mismas con combinaciones de variables. \n",
    "\n",
    "Escriba código que:\n",
    "- Extienda las variables en los arrays `LXtrain` y `LXtest` a combinaciones de grado 2, y con variables sin repetir (es decir, con el argumento `interaction_only=True`).\n",
    "- Entrena un modelo de clasificación con regresión logística con las características resultantes\n",
    "- Compare el acierto de este modelo con el baseline y con los modelos anteriores\n",
    "- Pinte la curva ROC de este modelo y calcule el área bajo la curva\n",
    "- Imprima los valores de los pesos del modelo correspondiente a cada variable \n",
    "\n",
    "Discuta las diferencias entre este modelo y los anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Añadir variables categóricas con dummy encodings \n",
    "\n",
    "En la siguiente sección vamos a enriquecer los modelos añadiendo variables categóricas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Discretizar edad en 5 bins (10%)\n",
    "\n",
    "Vamos a comenzar discretizando la edad en 5 *bins*. Escriba código que\n",
    "- Discretice la variable `AGE` en 5 *bins* con aproximadamente el mismo número de clientes en cada bin, incluyendo una columna llamada 'AGE_bins' en los dataframes `train_df` y `test_df` con los números de *bin* correspondiente\n",
    "- Obtenga numpy arrays `X_train_cat_dummy` y `X_test_cat_dummy` con la codificación *dummy* de las variable `AGE_bins`\n",
    "- Extienda las observaciones añadiendo estos arrays a `LXtrain` y `LXtest` (no incluyáis las extensiones polinómicas). Eliminando la columna correspondiente a la variable `AGE`original.\n",
    "- Entrene un modelo de clasificación con regresión logística con las características resultantes\n",
    "- Compare el acierto de este modelo con el baseline y con los modelos anteriores\n",
    "- Pinte la curva ROC de este modelo y calcule el área bajo la curva\n",
    "- Imprima los valores de los pesos del modelo correspondiente a cada variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Añadir más variables categóricas: variables PAY_0 a PAY_6 e info sociodemográfica (10%)\n",
    "\n",
    "A continuación  vamos a añadir al modelo las variables que describen el histórico de los usos del crédito y de los retrasos en el pago y las variables `SEX`,`EDUCATION`, `MARRIAGE` y `AGE_bins` codificadas con *dummy encoding*.\n",
    ". Escriba código que: \n",
    "- Obtenga numpy arrays `X_train_cat_dummy` y `X_test_cat_dummy` con la codificación *dummy* de las variables `SEX`,`EDUCATION`,`MARRIAGE`, `PAY_0_dis`, `PAY_2_dis`, `PAY_3_dis`, `PAY_4_dis`, `PAY_5_dis` y `PAY_6_dis`\n",
    "- Extienda las observaciones añadiendo estos arrays a `LXtrain` y `LXtest` (no incluyáis las extensiones polinómicas). Eliminando la columna correspondiente a la variable `AGE`original.\n",
    "- Entrene un modelo de clasificación con regresión logística con las características resultantes\n",
    "- Compare el acierto de este modelo con el baseline y con los modelos anteriores\n",
    "- Pinte la curva ROC de este modelo y calcule el área bajo la curva\n",
    "- Imprima los valores de los pesos del modelo correspondiente a cada variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 OPCIONAL: métodos no lineales (10%, extra)\n",
    "\n",
    "**Este apartado es opcional: su nota se suma a la nota del proyecto, pero no es necesario para conseguir la máxima calificación.**\n",
    "\n",
    "Podemos cambiar la tecnología de clasificación por si acaso el modelo que mejor se ajuste a nuestros datos fuese no lineal. \n",
    "\n",
    "Escribid código que evalúe modelos construidos con $k$ vecinos más próximos. Emplead como juegos de características los del apartado anterior. Explorad el rango de vecinos entre 1 y 101 (no hace falta que probéis todos los valores, que la base de datos no es pequeña)\n",
    "\n",
    "Alternativamente podéis emplear [*Random Forest*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) explorando estos rangos de parámetros:\n",
    "- `n_estimators` \n",
    "- `max_leaf_nodes` o `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estudio de grupos demográficos\n",
    "\n",
    "En la última sección vamos a intentar mejorar la interpretabilidad de los modelos mediante la creción de unas variables que segmenten los clientes atendiendo a criterios sociodemográficos.\n",
    "\n",
    "En primer lugar vamos a definir los segmentos de clientes definidos por las variables `SEX`,`EDUCATION`,`MARRIAGE`,`AGE_bins`. Primero vamos a agrupar estas variables en una única variable categórica `GRUPO` que tomará distintos valores enteros en función de las combinaciones de estas variables.\n",
    "\n",
    "El siguiente código es una manera de conseguir esto. Básicamente cada grupo se codifica con un entero que resulta de sumar los siquientes valores:\n",
    "\n",
    "$$\n",
    "\\mbox{GRUPO}(x) = 1000 \\times x[\\mbox{'SEX'}] + 100 \\times x[\\mbox{'EDUCATION'}] + 10 \\times x[\\mbox{'MARRIAGE'}] + x[\\mbox{'AGE_bins'}] \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_cat = ['SEX','EDUCATION','MARRIAGE','AGE_bins']\n",
    "mascara = np.array([1000, 100, 10, 1])\n",
    "train_df.loc[:,'GRUPO'] = (train_df.loc[:,columns_cat].values).dot(mascara)\n",
    "test_df.loc[:,'GRUPO']= (test_df.loc[:,columns_cat].values).dot(mascara)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Grupos con dummy encoding y variables continuas (10%)\n",
    "\n",
    "La primera aproximación consiste en codificar *dummy encoding* la variable grupo. En este caso hay que pasarle al objeto `OneHotEncoder` un listado con las categorías que hay en cada característica porque puede que algún grupo minoritario aparezca en el conjunto de test pero no en el de entrenamiento, por lo que el codificador no va a ser capaz de aprender todos los valores de esa característica solo mirando el conjunto de entrenamiento.\n",
    "\n",
    "El siguiente código se encarga de hacer esto mismo. La salida de este código son dos variables a tener en cuenta:\n",
    "- `lista_grupo`: lista de python con todos los valores que puede tomar la variable `GRUPO`\n",
    "- `dict_grupo`: diccionario de python donde cada valor que puede tomar la variable `GRUPO` se empareja con una cadena de caracteres que describe el segmento de clientes que codifica este valor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_values = []\n",
    "for cc,mm in zip(['SEX','EDUCATION','MARRIAGE','AGE_bins'], mascara):\n",
    "    lista_values.append([(jj)*mm for jj in np.unique(train_df[cc].values)])\n",
    "print(lista_values)\n",
    "import itertools\n",
    "lista_grupo = []\n",
    "dict_grupo = {}\n",
    "for element in itertools.product(*lista_values):\n",
    "    code_grupo = np.sum(np.asarray(element))\n",
    "    lista_grupo.append(code_grupo)\n",
    "    dict_grupo[code_grupo] = \"SEX_{0:d}_EDU_{1:d}_MAR_{2:d}_AGE_{3:d}\".format(int(element[0]/1000), \n",
    "                                                                              int(element[1]/100), \n",
    "                                                                              int(element[2]/10), \n",
    "                                                                              int(element[3]))   \n",
    "\n",
    "print(\"\")\n",
    "print(\"lista_grupo: \",lista_grupo)\n",
    "print(\"\")\n",
    "print(\"dict_grupo\",dict_grupo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escriba código que construya el argumento que se le debe pasar a la clase `OneHotEncoder` como argumento `categories` si queremos codificar *dummy encoding* las variables `GRUPO`, `PAY_0_dis`, `PAY_2_dis`, `PAY_3_dis`, `PAY_4_dis`, `PAY_5_dis` y `PAY_6_dis`. Este argumento debe ser un array de listas, donde cada elemento del array principal es la lista con todos los valores que debe tomar la categoría:\n",
    "\n",
    "`lista=[[lista_grupo],[lista_PAY_0_dis],...,[lista_PAY_6_dis]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación escribid código que:\n",
    "- Obtenga numpy arrays `X_train_cat_dummy` y `X_test_cat_dummy` con la codificación *dummy* de las variables `GRUPO`, `PAY_0_dis`, `PAY_2_dis`, `PAY_3_dis`, `PAY_4_dis`, `PAY_5_dis` y `PAY_6_dis`\n",
    "- Extienda las observaciones añadiendo estos arrays a `LXtrain` y `LXtest` (no incluyáis las extensiones polinómicas). Eliminando la columna correspondiente a la variable `AGE` original.\n",
    "- Entrene un modelo de clasificación con regresión logística con las características resultantes\n",
    "- Compare el acierto de este modelo con el baseline y con los modelos anteriores\n",
    "- Pinte la curva ROC de este modelo y calcule el área bajo la curva\n",
    "- Imprima los valores de los pesos del modelo correspondiente a cada variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3.3 Bin counting de los grupos con variables continuas y regresión logística (20%)\n",
    "\n",
    "Dado el gran número de grupos vamos a finalizar el *notebook* empleando conteos de *bins* para codificar esta variable\n",
    "\n",
    "En primer lugar escribid código que represente en el eje de las x una entrada por cada grupo y en el eje de las y el número de clientes que hay en ese grupo.\n",
    "\n",
    "¿Cuántos grupos tienen más de 100 clientes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bin_counter(object):\n",
    "    def __init__(self, back_off_threshold = 0):\n",
    "        self.back_off_threshold = back_off_threshold\n",
    "        self.backed_off_categories = []\n",
    "        pass\n",
    "    def fit_transform(self, x, y):\n",
    "        self.fit(x,y)\n",
    "        return self.transform(x)\n",
    "    def transform(self, x):\n",
    "        N = len(x)\n",
    "        output = np.empty((N, self.d))\n",
    "        x_categories = np.unique(x)\n",
    "        for cat in x_categories:\n",
    "            if cat not in self.code_book:\n",
    "                code = self.code_book['average']\n",
    "            elif cat in self.backed_off_categories:\n",
    "                code = self.code_book['back-off']\n",
    "            else:\n",
    "                code = self.code_book[cat]\n",
    "            posi = np.where(x==cat)[0]\n",
    "            output[posi,:] = code\n",
    "        return output\n",
    "    def fit(self, x, y):\n",
    "        self.code_book = {}\n",
    "        N = len(x)\n",
    "        y_categories = np.unique(y)\n",
    "        self.d = len(y_categories)\n",
    "        x_categories = np.unique(x)\n",
    "        num_x_categories = len(x_categories)\n",
    "        y_ohe = OneHotEncoder(sparse=False).fit_transform(y.reshape(-1,1))\n",
    "        back_off_counts = np.zeros(self.d)\n",
    "        num_back_off = 0\n",
    "        for cat in x_categories:\n",
    "            posi = np.where(x==cat)[0]\n",
    "            if len(posi) >= self.back_off_threshold:\n",
    "                code = np.mean(y_ohe[posi,:],0)\n",
    "                self.code_book[cat] = code\n",
    "            else:\n",
    "                self.backed_off_categories.append(cat)\n",
    "                back_off_counts += np.sum(y_ohe[posi,:],0)\n",
    "                num_back_off += len(posi)\n",
    "        if num_back_off > 0:\n",
    "            self.code_book['back-off']  = back_off_counts / num_back_off\n",
    "        self.code_book['average'] =  np.mean(y_ohe,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el efecto del *leakage* vamos a en primer lugar usar el conjunto de entrenamiento que hemos empleado hasta ahora para aprender los conteos de bin y el modelo de regresión logística. Complete la parte final de este código para entrenar el modelo y medir sus prestaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_leakage = bin_counter(back_off_threshold=100)\n",
    "train_grupo_bc = bc_leakage.fit_transform(train_df['GRUPO'].values, Y_train)\n",
    "test_grupo_bc = bc_leakage.transform(test_df['GRUPO'].values)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "- Codifica dummy encoding las variables PAY_0_dis', 'PAY_2_dis',\n",
    "       'PAY_3_dis', 'PAY_4_dis', 'PAY_5_dis', 'PAY_6_dis'\n",
    "- genera X_train_e  apilando las columnas de LXtrain, X_train_cat_dummy y train_df_bc[:,1]\n",
    "- genera X_test_e análogamente\n",
    "- entrena el modelo de regresión logística con X_train_e\n",
    "- evalúa el modelo (acierto en entrenamiento, acierto en test y area bajo la curva ROC)\n",
    "\"\"\"\n",
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora repetid el análisis de la celda anterior pero previamente dividiendo el conjunto de entrenamiento en dos mitades del mismo tamaño: \n",
    "- `train_bc_df` para aprender los conteos de bin y \n",
    "- `train_model_df` para entrenar el regresor logístico\n",
    "\n",
    "Comparad las prestaciones en ambos casos y evaluar el impacto del *leakage*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es el peso de la variable `GRUPO` codificada con conteo de bin en ambos casos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "\n",
    "\n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPCIONAL: interpretabilidad de los grupos demográficos (5%, extra)\n",
    "\n",
    "**Este apartado es opcional: su nota se suma a la nota del proyecto, pero no es necesario para conseguir la máxima calificación.**\n",
    "\n",
    "Ordenad los grupos de acuerdo a la probabilidad de default y verificar si hay muchas diferencias entre las primeras posiciones del *ranking*, las últimas, y los valores *back-off* y *average*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# YOUR CODE #\n",
    "#############\n",
    "        \n",
    "#######\n",
    "# END #\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
